{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the Names from Exotic Insects List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original GBIF Exotic data in excel format. Reading excel file using pandas \n",
    "data = pd.read_excel(\"imagefilename.xlsx\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_species = data['Original species name']\n",
    "list_species = list_species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for name in list_species[0:5]: \n",
    "    first = name.split()[0]\n",
    "    second = name.split()[1]\n",
    "    new_name = first + \"-\" + second\n",
    "    names.append(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (names[0]).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Below to reach the search page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path=r\"path/geckodriver-v0.23.0-win64/geckodriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_of_insect(name, searchUrl): \n",
    "    \n",
    "    for item in searchUrl:\n",
    "        try :     \n",
    "            if name in item:\n",
    "                return item\n",
    "        except TypeError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_of_image(next_url):\n",
    "    driver.get(next_url)\n",
    "    html = driver.page_source\n",
    "    soup = bs(html, \"lxml\")\n",
    "    link_list =[]\n",
    "\n",
    "    links  = soup.find_all(\"a\", class_=\"btn btn-primary btn-inat btn-xs\")\n",
    "    #links\n",
    "    for link in links:\n",
    "        link_list.append(link.get('href'))\n",
    "    \n",
    "    #print(link_list)\n",
    "    \n",
    "    url_of_insect = []\n",
    "    for links in link_list:\n",
    "        if \"/observations/\" in links:\n",
    "            url_of_insect.append(links)\n",
    "    #print(url_of_insect)\n",
    "    return url_of_insect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['/observations/18618656']\n",
      "[]\n",
      "['/observations/18819842']\n"
     ]
    }
   ],
   "source": [
    "urls_for_images = []\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    url = \"https://anywebsite/taxa/search?q=\"+name.lower()\n",
    "    driver.get(url)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = bs(html, \"lxml\")\n",
    "    links  = soup.find_all(\"a\")\n",
    "    #print(links)\n",
    "    searchUrl= []\n",
    "    for link in links:\n",
    "        searchUrl.append(link.get('href'))\n",
    "    #print(searchUrl)\n",
    "    #print(name)\n",
    "    different_species = []\n",
    "    url_of_insect = get_url_of_insect(name, searchUrl)\n",
    "    if url_of_insect is None:\n",
    "        different_species.append(name)\n",
    "        next_url = None\n",
    "    else:\n",
    "        next_url = \"https://anywebsite\" + url_of_insect\n",
    "    #print(url_of_insect)\n",
    "    #print(next_url)\n",
    "    \n",
    "    if next_url is None:\n",
    "        url_of_insect_2 = []\n",
    "    else:\n",
    "           \n",
    "        url_of_insect_2 = get_url_of_image(next_url)\n",
    "    \n",
    "    if len(url_of_insect_2) == 0:\n",
    "        urls_for_images.append(\"NA\")\n",
    "    else:\n",
    "        urls_for_images.append(url_of_insect_2[0])\n",
    "    print(url_of_insect_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_for_images = pd.DataFrame({\"name\" : names,  \"observation\" : urls_for_images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abgrallaspis-cyanophylli</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acallopais-rudis</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acantholybas-brunneus</td>\n",
       "      <td>/observations/18618656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acanthoscelides-obtectus</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acanthuchus-trispinifer</td>\n",
       "      <td>/observations/18819842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name             observation\n",
       "0  Abgrallaspis-cyanophylli                      NA\n",
       "1          Acallopais-rudis                      NA\n",
       "2     Acantholybas-brunneus  /observations/18618656\n",
       "3  Acanthoscelides-obtectus                      NA\n",
       "4   Acanthuchus-trispinifer  /observations/18819842"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_urls_for_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for i in range(len(df_urls_for_images['observation'])):\n",
    "    if df_urls_for_images['observation'][i] != \"NA\":\n",
    "        \n",
    "        urls.append(\"https://inaturalist.nz\"+df_urls_for_images['observation'][i])\n",
    "    else:\n",
    "        urls.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_for_images[\"urls\"] = urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICKING UP IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_links = []\n",
    "\n",
    "for i in range(len(df_urls_for_images['urls'])):\n",
    "    url = df_urls_for_images['urls'][i]\n",
    "    if url != 'NA':\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        soup = bs(html, \"lxml\")\n",
    "        links  = soup.find(\"div\", class_ = \"image-gallery-image\").find_all(\"img\", src=True)\n",
    "        for link in links:\n",
    "            imgUrl = link.get('src')\n",
    "            image_links.append(imgUrl)\n",
    "    else:\n",
    "        image_links.append(\"NA\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>observation</th>\n",
       "      <th>urls</th>\n",
       "      <th>image_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abgrallaspis-cyanophylli</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acallopais-rudis</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acantholybas-brunneus</td>\n",
       "      <td>/observations/18618656</td>\n",
       "      <td>https://inaturalist.nz/observations/18618656</td>\n",
       "      <td>https://static.inaturalist.org/photos/28496503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acanthoscelides-obtectus</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acanthuchus-trispinifer</td>\n",
       "      <td>/observations/18819842</td>\n",
       "      <td>https://inaturalist.nz/observations/18819842</td>\n",
       "      <td>https://static.inaturalist.org/photos/28827275...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name             observation  \\\n",
       "0  Abgrallaspis-cyanophylli                      NA   \n",
       "1          Acallopais-rudis                      NA   \n",
       "2     Acantholybas-brunneus  /observations/18618656   \n",
       "3  Acanthoscelides-obtectus                      NA   \n",
       "4   Acanthuchus-trispinifer  /observations/18819842   \n",
       "\n",
       "                                           urls  \\\n",
       "0                                            NA   \n",
       "1                                            NA   \n",
       "2  https://inaturalist.nz/observations/18618656   \n",
       "3                                            NA   \n",
       "4  https://inaturalist.nz/observations/18819842   \n",
       "\n",
       "                                         image_links  \n",
       "0                                                 NA  \n",
       "1                                                 NA  \n",
       "2  https://static.inaturalist.org/photos/28496503...  \n",
       "3                                                 NA  \n",
       "4  https://static.inaturalist.org/photos/28827275...  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_urls_for_images[\"image_links\"] = image_links\n",
    "df_urls_for_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Firefox(executable_path=r\"T:/projects/2018/SCION/geckodriver-v0.23.0-win64/geckodriver.exe\")\n",
    "# url = \"https://inaturalist.nz/observations/18618656\"\n",
    "# driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = driver.page_source\n",
    "# soup = bs(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://static.inaturalist.org/photos/28496503/large.jpeg?1543131054\n"
     ]
    }
   ],
   "source": [
    "# links  = soup.find(\"div\", class_ = \"image-gallery-image\").find_all(\"img\", src=True)\n",
    "# for link in links:\n",
    "#     imgUrl = link.get('src')\n",
    "#     print(imgUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(name, url):\n",
    "    local_filename = url.split('/')[-1]\n",
    "    \n",
    "    local_filename = local_filename.split(\"?\")[0]\n",
    "    print(local_filename)\n",
    "    print(\"Downloading {} ---> {}\".format(url, local_filename))\n",
    "    # NOTE the stream=True parameter\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(name+'.jpeg', 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large.jpeg\n",
      "Downloading https://static.inaturalist.org/photos/28496503/large.jpeg?1543131054 ---> large.jpeg\n",
      "large.jpeg\n",
      "Downloading https://static.inaturalist.org/photos/28827275/large.jpeg?1543908715 ---> large.jpeg\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_urls_for_images['image_links'])):\n",
    "    \n",
    "    url = df_urls_for_images['image_links'][i]\n",
    "    name = df_urls_for_images['name'][i]\n",
    "    if url != 'NA':\n",
    "        download_file(name, url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
